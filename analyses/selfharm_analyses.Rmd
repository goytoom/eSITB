---
title: "sharing_is_caring_analyses"
author: "Suhaib Abdurahman"
date: '2022-07-22'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages

```{r}
#library(tidyverse,  lib.loc = "/usr/lib/R/site-library")
library(tidyverse)
library(sjPlot)  # for plotting effects
library(modelsummary)  # for making tables
library(rstudioapi)
library(kableExtra)
library(data.table)
# library(stargazer)
# library(magick)
# library(gtsummary)
theme_set(theme_bw())  # Theme; just my personal preference
```

# Moral/Non-moral
## Load Data

```{r}
setwd("H:/My Drive/PhD/Research/self-injury/original/src")

#load data - choose best performing number of topics (here 26)
path_m = "../data/results/merged_data_all_moral_26.csv"
df_m = read_csv(path_m)  %>% filter(!(type == "comment" & is.na(parent_num_comments)) & !(type == "post" & is.na(num_comments))) #remove empty rows
df_m = df_m %>% filter(subreddit != "gme_suicidewatch") #remove unwanted subreddit (error in collection!)

#load cluster names (manually created by clinical psychologist based on key phrases and examples)
path_topics = "../data/results/topic_26_named.csv"
df_topics = read_csv(path_topics) %>% dplyr::select(Dominant_Topic, Topic_Name)
df_m[is.na(df_m$title),]$title = "" #keep emtpy strings as strings and not NA

#merge message data with topic information
df_m <- merge(df_m, df_topics, by = "Dominant_Topic", all.x = T)
df_m$Topic_Name <- relevel(factor(df_m$Topic_Name),"negative_thoughts")

# reformat variable and create control variables
df_cleaned_m <- df_m %>% mutate(Dominant_Topic = factor(Dominant_Topic), 
                                moral=factor(moral),
                                combined_text = paste(title, text, sep = " ")) %>% 
    mutate(n_words = stringr::str_count(combined_text, '\\S+'),
           engagement = ifelse(!is.na(num_comments), num_comments, parent_num_comments))

```

## Descriptive stats

```{r}
#Percentage of r/SuicideWatch among Subreddits:
df_cleaned_m %>% group_by(subreddit) %>% summarise(freq_subreddit = n()) %>% mutate(perc_subreddit = round(freq_subreddit/nrow(df_cleaned_m), 3))
 #~82.4% suicide watch

#frequency by message type
df_cleaned_m %>% group_by(type) %>% summarise(freq = n())

#frequency of moral messages
df_cleaned_m %>% summarise(total_perc_moral_messages = mean(moral==1)) #%38.7% moral messages in total
df_cleaned_m %>% group_by(type) %>% summarise(perc_moral_messages = round(mean(moral==1),3)) #%33% in comments, 49% in posts

#Topic distribution
topic_dist_m <- df_cleaned_m %>% group_by(Topic_Name) %>% dplyr::summarise(n=n()) %>% 
  mutate(Topic_Percentage = n/sum(n)) %>% arrange(desc(Topic_Percentage)) %>% dplyr::select(-n) 

topic_dist_m %>% kbl() %>% kable_material(c("striped", "hover"))
```


## Models

```{r}
lm_m_1 <- lm(score ~ Topic_Name*moral + n_words + engagement, df_cleaned_m)  
(coef(lm_m_1)["moral1"] + coef(lm_m_1)["(Intercept)"])/coef(lm_m_1)["(Intercept)"] # 5.6 times more likes for moral posts get, when controlling for all other variables

summary(lm_m_1) #model output 
```

## Plots
### Distributions

Create plots for the distribution of conversation topics and moral concerns across messages (frequency)
```{r}
#Topics
ggplot(data=topic_dist_m, aes(x=Topic_Name, fill=Topic_Name)) + 
  geom_bar(aes(x=Topic_Name,y=Topic_Percentage),stat="identity") + theme(axis.text.x = element_text(angle=90, hjust=1))

#Moral Concerns
df_plot = df_cleaned_m %>% group_by(type) %>% dplyr::summarise(perc = sum(moral==1)/n())
ggplot(data=df_plot, aes(x=type, fill=type)) + geom_bar(aes(x=type,y=perc),stat="identity", position="dodge") + ylab("Percent of posts with moral concerns") + xlab('Post type') + labs(fill="Post type") + guides(fill="none") + theme_bw() 
```

### Main Effects

Show the main effect of moral concerns on message likes
```{r}
#make nicer
plot_model(lm_m_1, type = "pred", terms=c("moral"))
```

### Interactions

Show the interaction of conversation topic and expressing moral concerns on message likes
```{r}
plot_model(lm_m_1, type = "pred", terms=c("Topic_Name", "moral")) + theme(axis.text.x = element_text(angle=90, hjust=1))
```


# All Foundations
## Load Data

```{r message=F, warning=F}
setwd("H:/My Drive/PhD/Research/self-injury/original/src")

path_a = "../data/results/merged_data_all_full_26.csv"
path_topics = "../data/results/topic_26_named.csv"

#load data and topics information
df_a = read_csv(path_a) %>% filter(!(type == "comment" & is.na(parent_num_comments)) & !(type == "post" & is.na(num_comments)))
#remove empty rows

df_topics = read_csv(path_topics) %>% dplyr::select(Dominant_Topic, Topic_Name)
df_a[is.na(df_a$title),]$title = "" #keep empty title as empty string and not NA

#merge data
df_a <- merge(df_a, df_topics, by = "Dominant_Topic", all.x = T)
df_a$Topic_Name <- relevel(factor(df_a$Topic_Name),"negative_thoughts") #put negative thoughts as reference point

# clean data: add word count and filter posts with no comment (not enough engagement/views)
# word count as control variable (message length)
df_cleaned_a <- df_a %>% mutate(Dominant_Topic = factor(Dominant_Topic), 
                                care=factor(care), fairness=factor(fairness),
                                loyalty=factor(loyalty), 
                                authority=factor(authority), 
                                purity=factor(purity), 
                                log_score = scale(sign(score) * log(abs(score) + 1)), #log modulus transformation (count data with negative values)
                                combined_text = paste(title, text, sep = " ")) %>%
                                mutate(n_words = stringr::str_count(combined_text, '\\S+'),
                                       engagement = ifelse(!is.na(num_comments), num_comments, parent_num_comments))
```

## Descriptive Stats

Create descriptive stats tables (e.g., distribution of each type of moral concerns in all messages and among messages with moral concerns)
```{r}
#distribution of each type of moral concern among all messages
df_cleaned_a %>% dplyr::select(care, fairness, loyalty, authority, purity) %>% dplyr::summarise(care = round(sum(care==1)/n()*100,1), #20.3%
                                                         fairness = round(sum(fairness==1)/n()*100,1), #1%
                                                         loyalty = round(sum(loyalty==1)/n()*100,1), #1%
                                                         authority = round(sum(authority==1)/n()*100,1), #0.1%
                                                         purity = round(sum(purity==1)/n()*100,1)) %>% kbl() %>%   kable_material(c("striped", "hover"))

# distribution of each type of moral concerns among message with a moral concern
df_cleaned_a %>% filter(care==1 | fairness==1 | loyalty==1 | authority==1 | purity==1) %>% dplyr::select(care, fairness, loyalty, authority, purity) %>% dplyr::summarise(care = round(sum(care==1)/n()*100,1), #20.3%
                                                         fairness = round(sum(fairness==1)/n()*100,1), #1%
                                                         loyalty = round(sum(loyalty==1)/n()*100,1), #1%
                                                         authority = round(sum(authority==1)/n()*100,1), #0.1%
                                                         purity = round(sum(purity==1)/n()*100,1)) %>% kbl() %>%   kable_material(c("striped", "hover"))
                                                          # 0.3% purity -> 25%moral

# Distribution of conversation topics among all messages
topics_distribution <- df_cleaned_a %>% group_by(Topic_Name)%>% summarise(n = n()) %>% mutate(freq = round(n / sum(n)*100, 1)) %>% ungroup() %>% arrange(desc(freq))

topics_distribution
```

Determine moral messages without identified type of moral concern ("Thin-Morality")
```{r}
#which/how many moral messages have no foundation associated?
moral_labels <- df_cleaned_m %>% select(id, moral)
foundation_labels <- df_cleaned_a %>% select(id, care, fairness, loyalty, authority, purity)

all_labels <- merge(moral_labels, foundation_labels, by = 'id')

all_labels %>% filter(moral==1 & care==0 & fairness==0 & loyalty==0 & authority==0 & purity==0) %>% dplyr::summarise(n(), n()/nrow(all_labels))
all_labels %>% filter(moral==0 & care==0 & fairness==0 & loyalty==0 & authority==0 & purity==0) %>% dplyr::summarise(n(), n()/nrow(all_labels))

ids <- all_labels %>% filter(moral==1 & care==0 & fairness==0 & loyalty==0 & authority==0 & purity==0) %>% select(id)

# get some examples 
df_cleaned_a %>% select(id, text) %>% filter(id %in% ids[3:4,]) %>% pull(text)
```


## Fit Model

Train regression models of conversation topics, moral concerns and control variables. This code fits multiple models in order to compare predictor contributions.
```{r}
# Full data
lm_a_1 <- lm(score ~ Topic_Name*(care+fairness+loyalty+authority+purity) + n_words + engagement, df_cleaned_a) #full model with all interactions
summary(lm_a_1) #NSSI concealment gets most likes

## model comparison
lm_a_0 <- lm(score ~ n_words + engagement, df_cleaned_a) # no predictors
lm_a_2 <- lm(score ~ Topic_Name + (care+fairness+loyalty+authority+purity) + n_words + engagement, df_cleaned_a) #no interactions
lm_a_3 <- lm(score ~ Topic_Name + n_words + engagement, df_cleaned_a) #no concerns
lm_a_4 <- lm(score ~ (care+fairness+loyalty+authority+purity) + n_words + engagement, df_cleaned_a) # only concerns

anova(lm_a_0, lm_a_1) # adding topics significantly adds to the model
anova(lm_a_0, lm_a_4) # adding concerns significantly adds to the model
anova(lm_a_3, lm_a_4) # topics explain more than concerns
anova(lm_a_4, lm_a_2) # adding topics to concerns adds significantly
anova(lm_a_3, lm_a_2) # adding moral concerns adds significantly to the model
anova(lm_a_2, lm_a_1) # adding interactions of concerns and topics adds significantly to the model
```


Print out regression coefficients of the main model.
```{r}
#sorted regression coefficient table
gt_1 <- lm_a_1 %>% 
  gtsummary::tbl_regression() %>% bold_labels() %>%
  gtsummary::modify_caption("Table 1: Summary Statistics of Reddit Karma by message topic and moral concerns")# %>% gt::as_latex()

gt::gtsave(as_gt(gt_1), file = "temp.tex")
gt::gtsave(as_gt(gt_1), file = "temp.rtf")

```


## Plots

### Distribution

Create distribution plots.
```{r}
#Moral Concerns
df_plot = df_cleaned_a %>% group_by(type) %>% dplyr::summarise(care = sum(care==1)/n(), fairness = sum(fairness==1)/n(),
                                                        loyalty = sum(loyalty==1)/n(), authority = sum(authority==1)/n(), purity = sum(purity==1)/n())
df_plot <- df_plot %>% gather(-type, key="Concern", value = "Percentage")
ggplot(data=df_plot, aes(x=type, fill=Concern)) + geom_bar(aes(x=type,y=Percentage),stat="identity", position="dodge") + ylab("Percent of posts with moral concerns") + xlab('Post type') + labs(fill="Moral Concern") + theme_bw()
```

### Main Effects

Create plots for each main effect.
```{r}
#needs to be improved!
plot_model(lm_a_1, type = "pred", terms=c("care")) + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms=c("fairness")) + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms=c("loyalty")) + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms=c("authority")) + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms=c("purity")) + theme(axis.text.x = element_text(angle=90, hjust=1))
```

### Interactions

Create plots for each interaction effect of moral concern x conversation topic
```{r}
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "care"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "purity"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "fairness"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "loyalty"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "authority"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
```


### Additional Information
#### Examples for moral foundations

Following codes extract examples of messages with a given moral concern or conversation topic.
```{r}
# Get examples for moral values (from comments/posts)

# 
df_cleaned_a_long <- df_a %>% mutate(Dominant_Topic = factor(Dominant_Topic)) %>% filter(!(type=="post" & num_comments<10) & !(type=="comment" & parent_num_comments < 10)) %>% mutate(moral_count = rowSums(select(., c(care, fairness, loyalty, authority, purity)))) %>% filter(moral_count == 1 | moral_count == 0) %>% mutate(non_moral = ifelse(moral_count==0, 1, 0)) %>% pivot_longer(c(care, fairness, loyalty, authority, purity, non_moral), names_to = "moral", values_to = "value")

#text can be "deleted" or "removed" for posts, then look at title!
set.seed(0)
moral_examples <- df_cleaned_a_long %>% filter(value==1) %>% dplyr::select(type, moral, title, text) %>% group_by(type, moral) %>% sample_n(10) %>% ungroup()
```


Get example messages.
```{r}
#moral values by number (1-6: care, fairness, loyalty, authority, purity, non-moral)
nr_val = 6 
moral_vals <- unique(moral_examples$moral)
mval <- moral_vals[nr_val] # convert number to moral concern name

nr = 5 #number of example

# print name of concern, example message title & text body
print(mval)
moral_examples[moral_examples$moral==mval,]$title[nr]
print("")
moral_examples[moral_examples$moral==mval,]$text[nr]
```


#### Examples for Topics

Get example messages for the respective topics
```{r}
# Note, topic loading/match reflects how much a message reflects elements of a given topic, therefore a message can load highly on multiple topics

# Extract the 10 messages with the highest load on the respective topic 
topics_examples <- df_a %>% group_by(Dominant_Topic) %>% arrange(desc(Topic_Perc_Contrib)) %>% do(head(., n=10))
topics_examples_showcase <- topics_examples %>% dplyr::select(Topic_Name, Dominant_Topic, Topic_Perc_Contrib, title, text)

# topics_examples_showcase %>% dplyr::select(Topic_Name, title, text) %>% head(15) # dplyr::select columns
```


Print out examples (by row -> check data frame for which row belongs to which topic)
```{r}
nr = 253
topics_examples_showcase$title[nr]
print("")
topics_examples_showcase$text[nr]
```


#### Examples for Moral Concerns expressed in a given Conversation topic (intersection of concerns and topics)

This code extracts messages of a given conversation topic that include a given moral concern.
```{r}
# Get examples for moral values (comments/posts)
df_cleaned_a_long <- df_a %>% mutate(Dominant_Topic = factor(Dominant_Topic)) %>% filter(!(type=="post" & num_comments<5) & !(type=="comment" & parent_num_comments < 5)) %>% mutate(moral_count = rowSums(select(., c(care, fairness, loyalty, authority, purity)))) %>% filter(moral_count == 1 | moral_count == 0) %>% mutate(non_moral = ifelse(moral_count==0, 1, 0)) %>% pivot_longer(c(care, fairness, loyalty, authority, purity, non_moral), names_to = "moral", values_to = "value")

#text can be "deleted" or "removed" for posts, then look at title!
#extract 7 messages with highest load on a given conversation topic that also include the respective moral concern
set.seed(0)
moral_examples_values <- df_cleaned_a_long %>% filter(value==1) %>% dplyr::select(type, moral, title, text, Topic_Name, Topic_Perc_Contrib) %>% group_by(Topic_Name, moral) %>% arrange(desc(Topic_Perc_Contrib)) %>% do(head(., n=7)) %>% ungroup()
```


Print out the examples by row (check data frame for which row corresponds to which topic and moral concern)
```{r}
nr = 1019
moral_examples_values$moral[nr]
as.character(moral_examples_values$Topic_Name[nr])
moral_examples_values$title[nr]
print("")
moral_examples_values$text[nr]

#3 authority x negative_thoughts
```


### Post/Comment relationships

Create a data frame that shows the most frequent conversation topic in the comments under a post with a given conversation topic.
How are topics in a post answered?
```{r message=F, warning=F}
df_posts_a <- df_cleaned_a %>% filter(type=="post") %>% dplyr::select(id, care, fairness, loyalty, authority, purity, Topic_Name, score)
df_comments_a <- df_cleaned_a %>% filter(type=="comment") %>% dplyr::select(id, parent_post, Topic_Name, care, fairness, loyalty, authority, purity, score)
df_paired_a <- merge(df_comments_a, df_posts_a, by.x="parent_post", by.y="id")
# df_paired_a$Topic_Name.y <- relevel(df_paired_a$Topic_Name.y, ref = "survival")

# get which Topic in posts has which topics in comments mostly
df_paired_freq <- df_paired_a %>% group_by(Topic_Name.y, Topic_Name.x) %>% summarise(n = n()) %>% mutate(freq = n / sum(n)) %>% group_by(Topic_Name.y) %>% arrange(desc(freq))

df_paired_freq_heatmap <- df_paired_freq %>% dcast(Topic_Name.y ~ Topic_Name.x)
rownames(df_paired_freq_heatmap) <- df_paired_freq_heatmap$Topic_Name.y
```


Show the most frequent topic in response to each topic in post as a table

```{r}
#kind of robustness check:
  # manual check of example messages
  # this check that looks into what topic is used to respond to a given topic (20 same topic, 6 different but related/reasonable!)

df_paired_freq %>% group_by(Topic_Name.y) %>% arrange(desc(freq)) %>% do(head(., n=1)) %>% mutate(freq = round(freq*100,1)) #y = post, x = comment
```



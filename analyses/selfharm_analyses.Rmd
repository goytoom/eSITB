---
title: "selfharm_analyses"
author: "Suhaib Abdurahman"
date: '2022-07-22'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages

```{r}
#library(tidyverse,  lib.loc = "/usr/lib/R/site-library")
library(tidyverse)
library(sjPlot)  # for plotting effects
library(modelsummary)  # for making tables
library(rstudioapi)
library(kableExtra)
library(data.table)
library(stargazer)
library(magick)
library(gtsummary)
theme_set(theme_bw())  # Theme; just my personal preference
```


# Moral/Non-moral
## Load Data

```{r}
#load data
path_m = "../data/results/merged_data_all_moral_26.csv"
df_m = read_csv(path_m)  %>% filter(!(type == "comment" & is.na(parent_num_comments)) & !(type == "post" & is.na(num_comments))) #remove empty rows
df_m = df_m %>% filter(subreddit != "gme_suicidewatch") #remove unwanted subreddit (error in collection!)
path_topics = "../data/results/topic_26_named.csv"
df_topics = read_csv(path_topics) %>% dplyr::select(Dominant_Topic, Topic_Name)
df_m[is.na(df_m$title),]$title = "" #keep emtpy strings as strings and not NA

#merge data with topic information
df_m <- merge(df_m, df_topics, by = "Dominant_Topic", all.x = T)
df_m$Topic_Name <- relevel(factor(df_m$Topic_Name),"negative_thoughts")

# reformat variable and create control variables
df_cleaned_m <- df_m %>% mutate(Dominant_Topic = factor(Dominant_Topic), 
                                moral=factor(moral),
                                combined_text = paste(title, text, sep = " ")) %>% 
    mutate(n_words = stringr::str_count(combined_text, '\\S+'),
           engagement = ifelse(!is.na(num_comments), num_comments, parent_num_comments))

```

## Descriptive stats

```{r}
#Percentage of r/SuicideWatch among Subreddits:
df_cleaned_m %>% group_by(subreddit) %>% summarise(freq_subreddit = n()) %>% mutate(perc_subreddit = round(freq_subreddit/nrow(df_cleaned_m), 3))
 #~82.4% suicide watch

#frequency by message type
df_cleaned_m %>% group_by(type) %>% summarise(freq = n())

#frequency of moral messages
df_cleaned_m %>% summarise(total_perc_moral_messages = mean(moral==1)) #%38.7% moral messages in total
df_cleaned_m %>% group_by(type) %>% summarise(perc_moral_messages = round(mean(moral==1),3)) #%33% in comments, 49% in posts

#Topic distribution
topic_dist_m = df_cleaned_m %>% group_by(Topic_Name) %>% dplyr::summarise(n=n()) %>% 
  mutate(Topic_Percentage = n/sum(n)) %>% arrange(desc(Topic_Percentage)) %>% dplyr::select(-n) 

topic_dist_m %>% kbl() %>% kable_material(c("striped", "hover"))
```


## Models

```{r}
lm_m_1 <- lm(score ~ Topic_Name*moral + n_words + engagement, df_cleaned_m)  
(coef(lm_m_1)["moral1"] + coef(lm_m_1)["(Intercept)"])/coef(lm_m_1)["(Intercept)"] # 5.6 times more likes for moral posts get, when controlling for all other variables

summary(lm_m_1)
```

## Plots
### Distributions
```{r}
#Topics
ggplot(data=topic_dist_m, aes(x=Topic_Name, fill=Topic_Name)) + 
  geom_bar(aes(x=Topic_Name,y=Topic_Percentage),stat="identity") + theme(axis.text.x = element_text(angle=90, hjust=1))

#Moral Concerns
df_plot = df_cleaned_m %>% group_by(type) %>% dplyr::summarise(perc = sum(moral==1)/n())
ggplot(data=df_plot, aes(x=type, fill=type)) + geom_bar(aes(x=type,y=perc),stat="identity", position="dodge") + ylab("Percent of posts with moral concerns") + xlab('Post type') + labs(fill="Post type") + guides(fill="none") + theme_bw() 
```

### Main Effects

```{r}
#make nicer
plot_model(lm_m_1, type = "pred", terms=c("moral"))
```

### Interactions

```{r}
plot_model(lm_m_1, type = "pred", terms=c("Topic_Name", "moral")) + theme(axis.text.x = element_text(angle=90, hjust=1))
```


# All Foundations
## Load Data

```{r message=F, warning=F}
path_a = "../data/results/merged_data_all_full_26.csv"
path_topics = "../data/results/topic_26_named.csv"

#load data and topics information
df_a = read_csv(path_a) %>% filter(!(type == "comment" & is.na(parent_num_comments)) & !(type == "post" & is.na(num_comments)))
#remove empty rows

df_topics = read_csv(path_topics) %>% dplyr::select(Dominant_Topic, Topic_Name)
df_a[is.na(df_a$title),]$title = "" #keep empty title as empty string and not NA

#merge data
df_a <- merge(df_a, df_topics, by = "Dominant_Topic", all.x = T)
df_a$Topic_Name <- relevel(factor(df_a$Topic_Name),"negative_thoughts") #put negative thoughts as reference point

# clean data: add word count and filter posts with no comment (not enough engagement/views)
df_cleaned_a <- df_a %>% mutate(Dominant_Topic = factor(Dominant_Topic), 
                                care=factor(care), fairness=factor(fairness),
                                loyalty=factor(loyalty), 
                                authority=factor(authority), 
                                purity=factor(purity), 
                                log_score = scale(sign(score) * log(abs(score) + 1)),
                                combined_text = paste(title, text, sep = " ")) %>%
                                mutate(n_words = stringr::str_count(combined_text, '\\S+'),
                                       engagement = ifelse(!is.na(num_comments), num_comments, parent_num_comments))
```

## Descriptive Stats
```{r}
#all
df_cleaned_a %>% dplyr::select(care, fairness, loyalty, authority, purity) %>% dplyr::summarise(care = round(sum(care==1)/n()*100,1), #20.3%
                                                         fairness = round(sum(fairness==1)/n()*100,1), #1%
                                                         loyalty = round(sum(loyalty==1)/n()*100,1), #1%
                                                         authority = round(sum(authority==1)/n()*100,1), #0.1%
                                                         purity = round(sum(purity==1)/n()*100,1)) %>% kbl() %>%   kable_material(c("striped", "hover"))

#among moral ones
df_cleaned_a %>% filter(care==1 | fairness==1 | loyalty==1 | authority==1 | purity==1) %>% dplyr::select(care, fairness, loyalty, authority, purity) %>% dplyr::summarise(care = round(sum(care==1)/n()*100,1), #20.3%
                                                         fairness = round(sum(fairness==1)/n()*100,1), #1%
                                                         loyalty = round(sum(loyalty==1)/n()*100,1), #1%
                                                         authority = round(sum(authority==1)/n()*100,1), #0.1%
                                                         purity = round(sum(purity==1)/n()*100,1)) %>% kbl() %>%   kable_material(c("striped", "hover"))
                                                          # 0.3% purity -> 25%moral

topics_distribution <- df_cleaned_a %>% group_by(Topic_Name)%>% summarise(n = n()) %>% mutate(freq = round(n / sum(n)*100, 1)) %>% ungroup() %>% arrange(desc(freq))

topics_distribution
```

```{r}
#which/how many moral messages have no foundation associated?
moral_labels <- df_cleaned_m %>% select(id, moral)
foundation_labels <- df_cleaned_a %>% select(id, care, fairness, loyalty, authority, purity)

all_labels <- merge(moral_labels, foundation_labels, by = 'id')

all_labels %>% filter(moral==1 & care==0 & fairness==0 & loyalty==0 & authority==0 & purity==0) %>% dplyr::summarise(n(), n()/nrow(all_labels))
all_labels %>% filter(moral==0 & care==0 & fairness==0 & loyalty==0 & authority==0 & purity==0) %>% dplyr::summarise(n(), n()/nrow(all_labels))

ids <- all_labels %>% filter(moral==1 & care==0 & fairness==0 & loyalty==0 & authority==0 & purity==0) %>% select(id)

# get some examples 
df_cleaned_a %>% select(id, text) %>% filter(id %in% ids[3:4,]) %>% pull(text)

```



## Fit Model

```{r}
# Full data
lm_a_1 <- lm(score ~ Topic_Name*(care+fairness+loyalty+authority+purity) + n_words + engagement, df_cleaned_a) #full model with all interactions
summary(lm_a_1) #NSSI concealment gets most likes

## model comparison
lm_a_0 <- lm(score ~ n_words + engagement, df_cleaned_a) # no predictors
lm_a_2 <- lm(score ~ Topic_Name + (care+fairness+loyalty+authority+purity) + n_words + engagement, df_cleaned_a) #no interactions
lm_a_3 <- lm(score ~ Topic_Name + n_words + engagement, df_cleaned_a) #no concerns
lm_a_4 <- lm(score ~ (care+fairness+loyalty+authority+purity) + n_words + engagement, df_cleaned_a) # only concerns

anova(lm_a_0, lm_a_1) # adding topics significantly adds to the model
anova(lm_a_0, lm_a_4) # adding concerns significantly adds to the model
anova(lm_a_3, lm_a_4) # topics explain more than concerns
anova(lm_a_4, lm_a_2) # adding topics to concerns adds significantly
anova(lm_a_3, lm_a_2) # adding moral concerns adds significantly to the model
anova(lm_a_2, lm_a_1) # adding interactions of concerns and topics adds significantly to the model
```

```{r}
#sorted regression coefficient table
gt_1 <- lm_a_1 %>% 
  gtsummary::tbl_regression() %>% bold_labels() %>%
  gtsummary::modify_caption("Table 1: Summary Statistics of Reddit Karma by message topic and moral concerns")# %>% gt::as_latex()

gt::gtsave(as_gt(gt_1), file = "temp.tex")
gt::gtsave(as_gt(gt_1), file = "temp.rtf")

```


## Plots

### Distribution
```{r}
#Moral Concerns
df_plot = df_cleaned_a %>% group_by(type) %>% dplyr::summarise(care = sum(care==1)/n(), fairness = sum(fairness==1)/n(),
                                                        loyalty = sum(loyalty==1)/n(), authority = sum(authority==1)/n(), purity = sum(purity==1)/n())
df_plot <- df_plot %>% gather(-type, key="Concern", value = "Percentage")
ggplot(data=df_plot, aes(x=type, fill=Concern)) + geom_bar(aes(x=type,y=Percentage),stat="identity", position="dodge") + ylab("Percent of posts with moral concerns") + xlab('Post type') + labs(fill="Moral Concern") + theme_bw()
```

### Main Effects
```{r}
#needs to be improved!
plot_model(lm_a_1, type = "pred", terms=c("care")) + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms=c("fairness")) + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms=c("loyalty")) + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms=c("authority")) + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms=c("purity")) + theme(axis.text.x = element_text(angle=90, hjust=1))
```

### Interactions
```{r}
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "care"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "purity"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "fairness"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "loyalty"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
plot_model(lm_a_1, type = "pred", terms = c("Topic_Name", "authority"))  + theme(axis.text.x = element_text(angle=90, hjust=1))
```


### Additional Information
#### Examples for moral foundations
```{r}
# Get examples for moral values (reddit comments/posts)
df_cleaned_a_long <- df_a %>% mutate(Dominant_Topic = factor(Dominant_Topic)) %>% filter(!(type=="post" & num_comments<10) & !(type=="comment" & parent_num_comments < 10)) %>% mutate(moral_count = rowSums(select(., c(care, fairness, loyalty, authority, purity)))) %>% filter(moral_count == 1 | moral_count == 0) %>% mutate(non_moral = ifelse(moral_count==0, 1, 0)) %>% pivot_longer(c(care, fairness, loyalty, authority, purity, non_moral), names_to = "moral", values_to = "value")

#text can be "deleted" or "removed" for posts, then look at title!
set.seed(0)
moral_examples <- df_cleaned_a_long %>% filter(value==1) %>% dplyr::select(type, moral, title, text) %>% group_by(type, moral) %>% sample_n(10) %>% ungroup()
```

```{r}
# get examples
nr_val = 6
moral_vals <- unique(moral_examples$moral)
mval <- moral_vals[nr_val]

nr = 5

print(mval)
moral_examples[moral_examples$moral==mval,]$title[nr]
print("")
moral_examples[moral_examples$moral==mval,]$text[nr]
```

#### Sort moral concerns by karma
```{r}
df_cleaned_a_moral <- df_a %>% mutate(Dominant_Topic = factor(Dominant_Topic)) %>% mutate(moral_count = rowSums(select(., c(care, fairness, loyalty, authority, purity)))) %>% mutate(non_moral = ifelse(moral_count==0, 1, 0)) %>% pivot_longer(c(care, fairness, loyalty, authority, purity, non_moral), names_to = "moral", values_to = "value")

df_cleaned_a_moral %>% group_by(moral) %>% filter(value==1) %>% dplyr::summarise(avg_karma = mean(score)) %>% arrange(desc(avg_karma))

# does not make sense, better to take the coefficients of the model!
```

#### Sort topics by karma
```{r}
df_cleaned_a %>% group_by(Topic_Name) %>% dplyr::summarise(avg_karma = mean(score, na.rm=T)) %>% arrange(desc(avg_karma))
```


#### Examples for Topics
```{r}
topics_examples <- df_a %>% group_by(Dominant_Topic) %>% arrange(desc(Topic_Perc_Contrib)) %>% do(head(., n=10))
topics_examples_showcase <- topics_examples %>% dplyr::select(Topic_Name, Dominant_Topic, Topic_Perc_Contrib, title, text)

# topics_examples_showcase %>% dplyr::select(Topic_Name, title, text) %>% head(15) # dplyr::select columns
```

```{r}
nr = 253
topics_examples_showcase$title[nr]
print("")
topics_examples_showcase$text[nr]
```

#### Examples for Topics by Moral Concern
```{r}
# Get examples for moral values (reddit comments/posts)
df_cleaned_a_long <- df_a %>% mutate(Dominant_Topic = factor(Dominant_Topic)) %>% filter(!(type=="post" & num_comments<5) & !(type=="comment" & parent_num_comments < 5)) %>% mutate(moral_count = rowSums(select(., c(care, fairness, loyalty, authority, purity)))) %>% filter(moral_count == 1 | moral_count == 0) %>% mutate(non_moral = ifelse(moral_count==0, 1, 0)) %>% pivot_longer(c(care, fairness, loyalty, authority, purity, non_moral), names_to = "moral", values_to = "value")

#text can be "deleted" or "removed" for posts, then look at title!
set.seed(0)
moral_examples_values <- df_cleaned_a_long %>% filter(value==1) %>% dplyr::select(type, moral, title, text, Topic_Name, Topic_Perc_Contrib) %>% group_by(Topic_Name, moral) %>% arrange(desc(Topic_Perc_Contrib)) %>% do(head(., n=7)) %>% ungroup()
```

```{r}
nr = 1019
moral_examples_values$moral[nr]
as.character(moral_examples_values$Topic_Name[nr])
moral_examples_values$title[nr]
print("")
moral_examples_values$text[nr]

#3 authority x negative_thoughts
```

### Post/Comment relationships

```{r message=F, warning=F}
df_posts_a <- df_cleaned_a %>% filter(type=="post") %>% dplyr::select(id, care, fairness, loyalty, authority, purity, Topic_Name, score)
df_comments_a <- df_cleaned_a %>% filter(type=="comment") %>% dplyr::select(id, parent_post, Topic_Name, care, fairness, loyalty, authority, purity, score)
df_paired_a <- merge(df_comments_a, df_posts_a, by.x="parent_post", by.y="id")
# df_paired_a$Topic_Name.y <- relevel(df_paired_a$Topic_Name.y, ref = "survival")

# get which Topic in posts has which topics in comments mostly
df_paired_freq <- df_paired_a %>% group_by(Topic_Name.y, Topic_Name.x) %>% summarise(n = n()) %>% mutate(freq = n / sum(n)) %>% group_by(Topic_Name.y) %>% arrange(desc(freq))

df_paired_freq_heatmap <- df_paired_freq %>% dcast(Topic_Name.y ~ Topic_Name.x)
rownames(df_paired_freq_heatmap) <- df_paired_freq_heatmap$Topic_Name.y

# sort by comment likes
# what are we interested here? it's less consistent than before but also some topics might generally receive more likes

df_paired_likes <- df_paired_a %>% group_by(Topic_Name.y, Topic_Name.x) %>% summarise(avg_likes = mean(score.x)) %>% group_by(Topic_Name.y) %>% arrange(desc(avg_likes)) 

df_paired_likes_heatmap <- df_paired_likes %>% dcast(Topic_Name.y ~ Topic_Name.x)
rownames(df_paired_likes_heatmap) <- df_paired_likes_heatmap$Topic_Name.y
```

### Show most frequent topic in response to each topic in post

```{r}
#kind of robustness check:
  # manual check of example messages
  # this check that looks into what topic is used to respond to a given topic (20 same topic, 6 different but related/reasonable!)

df_paired_freq %>% group_by(Topic_Name.y) %>% arrange(desc(freq)) %>% do(head(., n=1)) %>% mutate(freq = round(freq*100,1)) #y = post, x = comment
```


#### Analyze relationship
```{r}
#table
df_paired_freq_heatmap %>% dplyr::select(-Topic_Name.y) %>% kbl() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

# heatmap
ggplot(df_paired_freq, aes(Topic_Name.x, Topic_Name.y, fill= freq)) + 
  geom_tile() + scale_x_discrete(limits = rev(levels(df_paired_freq$Topic_Name.x))) + theme(axis.text.x = element_text(angle=90, hjust=1))

# nearly always is the most answered topic, the posted one! -> indication that the topic modelling is consistent!
# in cases where it is not the most responded it is a reasonable choice/consequence, e.g.: immediate_helpseeking is answered with experiences of ideation (makes sense since that is what the help seeking is mostly about), (problems with) loved ones answered by wishing_well. negative_emotionality by people_care!

#table
df_paired_likes_heatmap %>% dplyr::select(-Topic_Name.y) %>% kbl() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

# heatmap
ggplot(df_paired_likes, aes(Topic_Name.x, Topic_Name.y, fill= avg_likes)) + 
  geom_tile() + scale_x_discrete(limits = rev(levels(df_paired_likes$Topic_Name.x))) + theme(axis.text.x = element_text(angle=90, hjust=1))
```

```{r}
## run models -> check combination of post topic and comment value/Topic
lm_paired_0 <- lm(score.x ~ Topic_Name.y*Topic_Name.x + n_words.x + n_words.y, df_paired_a)
summary(lm_paired_0)

lm_paired_1 <- lm(score.x ~ Topic_Name.y*(care.x + fairness.x + loyalty.x + authority.x + purity.x) + Topic_Name.x + engagement.y, df_paired_a)
summary(lm_paired_1)
```





